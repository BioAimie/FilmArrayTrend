rolling.density <- c()
for(j in (train.weeks+1):(l-1)) {
# create the training set
# print(site.periods[j])
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
# if the data set is too small, then skip forward in time
if(nrow(train.set) < 10) { break() }
# on the fly, determine the number of clusters for this data set
# print('entering section to determine k')
wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
if(length(which(k.curve < 0))==0) {
k.centers <- max.clusters
} else {
k.centers <- min(which(k.curve < 0)) - 1
}
# perform k-means on the training set to get a cluster
# print('entering section to cluster using k-means')
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
# use kNN with these labels and then predict the clustering of the next week
# print('entering section to predict cluster using kNN as a training method')
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
predicted.set$Cluster <- predict(k.knn, newdata = predicted.set)
# find the change in density
# print('entering section to find the change in cluster density')
train.total <- nrow(train.set)
train.density <- with(data.frame(train.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
predict.total <- nrow(predicted.set)
shift.density <- with(data.frame(predicted.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
train.density$Density <- train.density$Count/train.total
shift.density$Density <- shift.density$Count/predict.total
# bind the data together to get a temporal view of density changes by site
# print('entering section to bind data')
temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoCluster = k.centers, MedianDensityShift = median(abs((train.density$Density - shift.density$Density))/train.density$Density), SdDensityShift = sd(abs((train.density$Density - shift.density$Density))/train.density$Density))
# temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoClusters = max(as.numeric(as.character(train.density$Cluster))), merge(train.density, shift.density, by='Cluster'))
rolling.density <- rbind(rolling.density, temp)
}
head(rolling.density)
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift, fill=NoCluster)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggplot(rolling.density, aes(x=YearWeek, y=SdDensityShift, fill=NoCluster)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggplot(rolling.density, aes(x=YearWeek, y=NoCluster*MedianDensityShift, fill=sdDensityShift)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggplot(rolling.density, aes(x=YearWeek, y=NoCluster*MedianDensityShift, fill=SdDensityShift)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
View(rolling.density)
rolling.density <- c()
for(j in (train.weeks+1):(l-1)) {
# create the training set
# print(site.periods[j])
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
# if the data set is too small, then skip forward in time
if(nrow(train.set) < 10) { break() }
# on the fly, determine the number of clusters for this data set
# print('entering section to determine k')
wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
if(length(which(k.curve < 0))==0) {
k.centers <- max.clusters
} else {
k.centers <- min(which(k.curve < 0)) - 1
}
# perform k-means on the training set to get a cluster
# print('entering section to cluster using k-means')
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
# use kNN with these labels and then predict the clustering of the next week
# print('entering section to predict cluster using kNN as a training method')
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
predicted.set$Cluster <- predict(k.knn, newdata = predicted.set)
# find the change in density
# print('entering section to find the change in cluster density')
train.total <- nrow(train.set)
train.density <- with(data.frame(train.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
predict.total <- nrow(predicted.set)
shift.density <- with(data.frame(predicted.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
train.density$Density <- train.density$Count/train.total
shift.density$Density <- shift.density$Count/predict.total
# bind the data together to get a temporal view of density changes by site
# print('entering section to bind data')
temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoCluster = k.centers, TrainingSetSize = train.total, NewSetSize = predict.total, MedianDensityShift = median(abs((train.density$Density - shift.density$Density))/train.density$Density), SdDensityShift = sd(abs((train.density$Density - shift.density$Density))/train.density$Density), RangeDensityShift=range(abs((train.density$Density - shift.density$Density))/train.density$Density))
# temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoClusters = max(as.numeric(as.character(train.density$Cluster))), merge(train.density, shift.density, by='Cluster'))
rolling.density <- rbind(rolling.density, temp)
}
head(rolling.density)
a <- unique(rolling.density[,1:7])
head(a)
ggplot(a, aes(x=YearWeek, y=MedianDensityShift)) + geom_bar(stat='identity')
ggplot(a, aes(x=YearWeek, y=MedianDensityShift*NoCluster)) + geom_bar(stat='identity')
ggplot(a, aes(x=YearWeek, y=MedianDensityShift*NoCluster)) + geom_bar(stat='identity') + theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
View(a)
lhead(cp.median)
head(cp.median)
cp.ordered <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(cp.median[cp.median$RunDataId==run.ids[x], ][order(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), ], Index = seq(1, length(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), 1))))
cp.sequence <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(RunDataId = run.ids[x], Sequence = paste(as.character(cp.ordered[cp.ordered$RunDataId==run.ids[x], 'AssayName']), collapse=', '))))
run.ids <- unique(cp.median$RunDataId)
cp.ordered <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(cp.median[cp.median$RunDataId==run.ids[x], ][order(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), ], Index = seq(1, length(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), 1))))
setwd('~/FilmArrayTrend/EnteroD68/')
# load the neccessary libraries
library(RODBC)
library(lubridate)
library(ggplot2)
library(devtools)
require(dateManip)
library(cluster)
library(caret)
library(dbscan)
library(C50)
library(tidyr)
library(dplyr)
# library(plot3D)
library(AnomalyDetection)
# create an Epi date calendar that will be used by all the data sets
startYear <- 2013
calendar.df <- createCalendarLikeMicrosoft(startYear, 'Week')
calendar.df <- transformToEpiWeeks(calendar.df)
calendar.df$YearWeek <- with(calendar.df, ifelse(Week < 10, paste(Year, Week, sep='-0'), paste(Year, Week, sep='-')))
# set up some constants
imgDir <- 'Figures/'
dateBreaks <- unique(calendar.df[calendar.df$Year >= startYear, 'YearWeek'])[order(unique(calendar.df[calendar.df$Year >= startYear, 'YearWeek']))][seq(1, length(unique(calendar.df[calendar.df$Year >= startYear, 'YearWeek'])), 8)]
# set some query variables, like the customer site... also, get the number of RP runs by site
FADWcxn <- odbcConnect('FA_DW', uid = 'afaucett', pwd = 'ThisIsAPassword-BAD')
queryVector <- scan('../DataSources/SQL/EnteroD68/sitesRunningRP.txt',what=character(),quote="")
query <- paste(queryVector,collapse=" ")
sites.df <- sqlQuery(FADWcxn,query)
queryVector <- scan('../DataSources/SQL/EnteroD68/rpRunsBySite.sql',what=character(),quote="")
query <- paste(queryVector,collapse=" ")
runs.df <- sqlQuery(FADWcxn,query)
odbcClose(FADWcxn)
# start a loop to gather Cp data for all sites running RP
cp.df <- c()
choose.sites <- as.character(sites.df[,'CustomerSiteId'])
for(j in 1:length(choose.sites)) {
FADWcxn <- odbcConnect('FA_DW', uid = 'afaucett', pwd = 'ThisIsAPassword-BAD')
queryVector <- scan('../DataSources/SQL/EnteroD68/rhinoDataBySite.sql', what=character(), quote="")
query <- paste(gsub('SITE_INDEX', choose.sites[j], queryVector), collapse=" ")
cp.site.df <- sqlQuery(FADWcxn, query)
odbcClose(FADWcxn)
cp.df <- rbind(cp.df, cp.site.df)
}
rm(cp.site.df)
# first, clean up the data to be in a format that will work for feature analysis (machine learning)
# ===========================================================================================
#   with the cp data, determine the median Cp of each assay in the HRV/EV target
cp.median <- aggregate(Cp~RunDataId+CustomerSiteId+Date+AssayName, FUN=median, data=cp.df)
cp.spread <- spread(data = cp.median, key = AssayName, value = Cp)
sparse.handler <- 40
cp.spread[,c(4:9)][is.na(cp.spread[,c(4:9)])] <- sparse.handler
#   only consider "good" data (assume a start of mid-2013)
cp.clean <- merge(cp.spread, filter(calendar.df[,c('Date','YearWeek')], YearWeek >= '2013-26'), by='Date')
# second, since the final algorithm should be run on a site-by-site basis, determine which sites are "eligible"
# ===========================================================================================
site.rhino.count <- with(merge(data.frame(cp.spread, Positive=1), calendar.df, by='Date'), aggregate(Positive~YearWeek+CustomerSiteId, FUN=sum))
sites <- as.character(unique(site.rhino.count$CustomerSiteId))[order(as.character(unique(site.rhino.count$CustomerSiteId)))]
site.rhino.count <- do.call(rbind, lapply(1:length(sites), function(x) data.frame(merge(data.frame(YearWeek = unique(calendar.df[,c('YearWeek')]), CustomerSiteId = sites[x]), site.rhino.count[site.rhino.count$CustomerSiteId==sites[x], c('YearWeek','Positive')], by='YearWeek', all.x=TRUE))))
site.rhino.count[is.na(site.rhino.count$Positive), 'Gap'] <- 1
site.rhino.count[is.na(site.rhino.count$Gap), 'Gap'] <- 0
periods <- unique(as.character(site.rhino.count$YearWeek))
site.gaps <- do.call(rbind, lapply(1:length(sites), function(x) do.call(rbind, lapply(5:length(periods), function(y) data.frame(YearWeek = periods[y], CustomerSiteId = sites[x], MissingPeriods = sum(site.rhino.count[site.rhino.count$CustomerSiteId==sites[x], 'Gap'][(y-4):y]))))))
site.starts <- do.call(rbind, lapply(1:length(sites), function(x) site.gaps[site.gaps$CustomerSiteId==sites[x],][max(which(site.gaps[site.gaps$CustomerSiteId==sites[x], 'MissingPeriods']==5)), c('CustomerSiteId','YearWeek')]))
# third, apply machine learning
# ===========================================================================================
#   determine labels
run.ids <- unique(cp.median$RunDataId)
cp.ordered <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(cp.median[cp.median$RunDataId==run.ids[x], ][order(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), ], Index = seq(1, length(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), 1))))
cp.sequence <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(RunDataId = run.ids[x], Sequence = paste(as.character(cp.ordered[cp.ordered$RunDataId==run.ids[x], 'AssayName']), collapse=', '))))
head(cp.sequence)
cp.features <- merge(cp.spread, calendar.df[,c('Date','YearWeek')], by='Date')
train.weeks <- 12
test.weeks <- 1
i <- 6
sites[i]
site.periods <- periods[periods > as.character(site.starts[site.starts$CustomerSiteId==sites[i],'YearWeek'])]
l <- length(site.periods)
if(l < (train.weeks+test.weeks)) { break() }
rolling.density <- c()
for(j in (train.weeks+1):(l-1)) {
# create the training set
# print(site.periods[j])
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
# if the data set is too small, then skip forward in time
if(nrow(train.set) < 40) { break() }
# on the fly, determine the number of clusters for this data set
# print('entering section to determine k')
# wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
# for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
# k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
# if(length(which(k.curve < 0))==0) {
#
#   k.centers <- max.clusters
# } else {
#
#   k.centers <- min(which(k.curve < 0)) - 1
# }
k.centers = 10
# perform k-means on the training set to get a cluster
# print('entering section to cluster using k-means')
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
# use kNN with these labels and then predict the clustering of the next week
# print('entering section to predict cluster using kNN as a training method')
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
predicted.set$Cluster <- predict(k.knn, newdata = predicted.set)
# find the change in density
# print('entering section to find the change in cluster density')
train.total <- nrow(train.set)
train.density <- with(data.frame(train.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
predict.total <- nrow(predicted.set)
shift.density <- with(data.frame(predicted.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
train.density$Density <- train.density$Count/train.total
shift.density$Density <- shift.density$Count/predict.total
# bind the data together to get a temporal view of density changes by site
# print('entering section to bind data')
temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoCluster = k.centers, TrainingSetSize = train.total, NewSetSize = predict.total, MedianDensityShift = median(abs((train.density$Density - shift.density$Density))/train.density$Density), SdDensityShift = sd(abs((train.density$Density - shift.density$Density))/train.density$Density), RangeDensityShift=range(abs((train.density$Density - shift.density$Density))/train.density$Density))
# temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoClusters = max(as.numeric(as.character(train.density$Cluster))), merge(train.density, shift.density, by='Cluster'))
rolling.density <- rbind(rolling.density, temp)
}
i
sites[i]
rolling.density <- c()
for(j in (train.weeks+1):(l-1)) {
# create the training set
# print(site.periods[j])
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
# if the data set is too small, then skip forward in time
if(nrow(train.set) < 40) { break() }
# on the fly, determine the number of clusters for this data set
# print('entering section to determine k')
# wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
# for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
# k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
# if(length(which(k.curve < 0))==0) {
#
#   k.centers <- max.clusters
# } else {
#
#   k.centers <- min(which(k.curve < 0)) - 1
# }
k.centers = 10
# perform k-means on the training set to get a cluster
# print('entering section to cluster using k-means')
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
# use kNN with these labels and then predict the clustering of the next week
# print('entering section to predict cluster using kNN as a training method')
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
predicted.set$Cluster <- predict(k.knn, newdata = predicted.set)
# find the change in density
# print('entering section to find the change in cluster density')
train.total <- nrow(train.set)
train.density <- with(data.frame(train.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
predict.total <- nrow(predicted.set)
shift.density <- with(data.frame(predicted.set, Count = 1), aggregate(Count~Cluster, FUN=sum))
train.density$Density <- train.density$Count/train.total
shift.density$Density <- shift.density$Count/predict.total
# bind the data together to get a temporal view of density changes by site
# print('entering section to bind data')
temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoCluster = k.centers, TrainingSetSize = train.total, NewSetSize = predict.total, MedianDensityShift = median(abs((train.density$Density - shift.density$Density))/train.density$Density), SdDensityShift = sd(abs((train.density$Density - shift.density$Density))/train.density$Density), MaxDensityShift=max(abs((train.density$Density - shift.density$Density))/train.density$Density), MinDensityShift=min(abs((train.density$Density - shift.density$Density))/train.density$Density))
# temp <- data.frame(CustomerSiteId = sites[i], YearWeek = site.periods[j+1], NoClusters = max(as.numeric(as.character(train.density$Cluster))), merge(train.density, shift.density, by='Cluster'))
rolling.density <- rbind(rolling.density, temp)
}
head(rolling.density)
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift, fill=NoCluster)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
head(rolling.density)
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift, fill=SdDensityShift)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift*SdDensityShift)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
head(cp.ordered)
cp.ordered[grep('HRV1', cp.ordered$AssayName), 'RunDataId']
head(cp.spread)
cp.labels <- cp.spread
head(cp.ordered)
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV1', 'RunDataId'],'F1'] <- 'H1'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV1', 'RunDataId'],'F1'] <- 'H1'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV2', 'RunDataId'],'F1'] <- 'H2'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV3', 'RunDataId'],'F1'] <- 'H3'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV4', 'RunDataId'],'F1'] <- 'H4'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='Entero1', 'RunDataId'],'F1'] <- 'E1'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='Entero2', 'RunDataId'],'F1'] <- 'E2'
head(cp.labels)
head(cp.labels)
cp.ordered[cp.ordered$Index==1, 'Cp']
head(cp.ordered)
cp.ordered[cp.ordered$Index==1, c('RunDataId','Cp')]
round(cp.ordered[cp.ordered$Index==1, 'Cp'])
head(cp.ordered[cp.ordered$Index==1, c('RunDataId','Cp')])
head(round(cp.ordered[cp.ordered$Index==1, 'Cp']))
head(cp.labels)
cp.labels$F2 <- round(cp.ordered[cp.ordered$Index==1, 'Cp'])
head(cp.labels)
nchar(cp.labels$F2)
ifelse(nchar(cp.labels$F2) < 2, paste('0',cp.labels$F2,sep=''), cp.labels$F2)
cp.labels$F2 <- ifelse(nchar(cp.labels$F2) < 2, paste('0',cp.labels$F2,sep=''), cp.labels$F2)
head(cp.ordered)
head(cp.labels)
cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]]
head(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]])
cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40
sum(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40)
apply(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40, 1, sum)
unname(apply(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40, 1, sum))
head(cp.labels)
paste('H', unname(apply(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40, 1, sum)), sep='')
cp.labels$F3 <- paste('H', unname(apply(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40, 1, sum)), sep='')
cp.labels$F4 <- paste('H', unname(apply(cp.labels[,colnames(cp.labels)[grep('Entero', colnames(cp.labels))]] < 40, 1, sum)), sep='')
head(cp.labels)
cp.labels$F4 <- paste('E', unname(apply(cp.labels[,colnames(cp.labels)[grep('Entero', colnames(cp.labels))]] < 40, 1, sum)), sep='')
head(cp.labels)
c(cp.labels[,10:13])
paste(cp.labels[,10:13], collapse='')
do.call(c, lapply(10:13, funciton(x) paste0(cp.labels[,x]))
do.call(c, lapply(10:13, funciton(x) paste0(cp.labels[,x])))
paste(cp.labels$F1, cp.labels$F2)
paste(cp.labels$F1, cp.labels$F2, sep='')
paste(cp.labels$F1, cp.labels$F2, cp.labels$F3, cp.labels$F4, sep='')
co.labels$Label <- paste(cp.labels$F1, cp.labels$F2, cp.labels$F3, cp.labels$F4, sep='')
cp.labels$Label <- paste(cp.labels$F1, cp.labels$F2, cp.labels$F3, cp.labels$F4, sep='')
head(cp.labels)
cp.labels <- merge(cp.labels, calendar.df[,c('Date','YearWeek')], by='Date')
head(cp.labels)
ggplot(cp.labels, aes(x=YearWeek, fill=Label)) + geom_bar()
with(data.frame(cp.labels, Record = 1), aggregate(Record~CustomerSiteId+Label+YearWeek, FUN=sum))
a <- with(data.frame(cp.labels, Record = 1), aggregate(Record~CustomerSiteId+Label+YearWeek, FUN=sum))
b <- with(data.frame(cp.labels, Record = 1), aggregate(Record~CustomerSiteId+YearWeek, FUN=sum))
head(a)
head(b)
merge(a, b, by=c('YearWeek','CustomerSiteId'))
d <- merge(a, b, by=c('YearWeek','CustomerSiteId'))
head(d)
d$Rate <- with(d, Record.x/Record.y)
head(d)
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + theme(legend.position = 'bottom')
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity')
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + scale_fill_continuous(low='red', high='white', guide=FALSE)
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + scale_fill_discrete(low='red', high='white', guide=FALSE)
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + theme(legend.position = 'none')
cp.ordered[cp.ordered$Index==1, 'Cp']
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30), labels=c('1','2','3','4','5','6','7'))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30), labels=c('1','2','3','4','5','6','7','8'))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30), labels=c('1','2','3','4','5','6','7'))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30), labels=c('1','2','3','4','5','6'))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 5, 10, 15, 20, 25, 30), labels=c('1','2','3','4','5','6'))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30))
cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30), labels=c('01','02','03','04','05','06','07','08','09','10'))
cp.labels$F2 <- cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30), labels=c('01','02','03','04','05','06','07','08','09','10'))
cp.labels$Label <- paste(cp.labels$F1, cp.labels$F2, cp.labels$F3, cp.labels$F4, sep='')
cp.labels <- merge(cp.labels, calendar.df[,c('Date','YearWeek')], by='Date')
head(cp.labels)
cp.labels <- cp.spread
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV1', 'RunDataId'],'F1'] <- 'H1'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV2', 'RunDataId'],'F1'] <- 'H2'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV3', 'RunDataId'],'F1'] <- 'H3'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='HRV4', 'RunDataId'],'F1'] <- 'H4'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='Entero1', 'RunDataId'],'F1'] <- 'E1'
cp.labels[cp.labels$RunDataId %in% cp.ordered[cp.ordered$Index==1 & cp.ordered$AssayName=='Entero2', 'RunDataId'],'F1'] <- 'E2'
# cp.labels$F2 <- round(cp.ordered[cp.ordered$Index==1, 'Cp'])
# cp.labels$F2 <- ifelse(nchar(cp.labels$F2) < 2, paste('0',cp.labels$F2,sep=''), cp.labels$F2)
cp.labels$F2 <- cut(cp.ordered[cp.ordered$Index==1, 'Cp'], breaks=c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30), labels=c('01','02','03','04','05','06','07','08','09','10'))
cp.labels$F3 <- paste('H', unname(apply(cp.labels[,colnames(cp.labels)[grep('HRV', colnames(cp.labels))]] < 40, 1, sum)), sep='')
cp.labels$F4 <- paste('E', unname(apply(cp.labels[,colnames(cp.labels)[grep('Entero', colnames(cp.labels))]] < 40, 1, sum)), sep='')
cp.labels$Label <- paste(cp.labels$F1, cp.labels$F2, cp.labels$F3, cp.labels$F4, sep='')
cp.labels <- merge(cp.labels, calendar.df[,c('Date','YearWeek')], by='Date')
a <- with(data.frame(cp.labels, Record = 1), aggregate(Record~CustomerSiteId+Label+YearWeek, FUN=sum))
b <- with(data.frame(cp.labels, Record = 1), aggregate(Record~CustomerSiteId+YearWeek, FUN=sum))
head(d)
d <- merge(a, b, by=c('YearWeek','CustomerSiteId'))
d$Rate <- with(d, Record.x/Record.y)
ggplot(subset(d, CustomerSiteId==26), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + theme(legend.position = 'none')
unique(d$Label)
head(cp.label)
head(cp.labels)
head(rolling.density)
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift)) + geom_bar(stat='identity')
min(rolling.density$YearWeek)
min(as.character(rolling.density$YearWeek))
ggplot(subset(d, CustomerSiteId==26 & YearWeek >= '2013-39'), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + theme(legend.position = 'none')
ggplot(rolling.density, aes(x=YearWeek, y=MedianDensityShift)) + geom_bar(stat='identity') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggplot(subset(d, CustomerSiteId==26 & YearWeek >= '2013-39'), aes(x=YearWeek, y=Rate, fill=Label)) + geom_bar(stat='identity') + theme(legend.position = 'none') + theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
rainbow(length(unique(d$Label)))
head(cp.features)
cp.features[cp.features$YearWeek %in% c('2014-31','2014-32','2014-33','2014-34','2014-35') & cp.features$CustomerSiteId=='26',]
m <- cp.features[cp.features$YearWeek %in% c('2014-31','2014-32','2014-33','2014-34','2014-35') & cp.features$CustomerSiteId=='26',]
head(m)
kmeans(m[,4:9], 10)
kmeans(m[,4:9], 10, 100)
kmeans(m[,4:9], 10, 100)$Cluster
kmeans(m[,4:9], 10, 100)$cluster
m$Cluster <- kmeans(m[,4:9], 10, 100)$cluster
head(m)
head(cp.labels)
n <- cp.labels[cp.labels$YearWeek %in% c('2014-31','2014-32','2014-33','2014-34','2014-35') & cp.labels$CustomerSiteId=='26',]
head(n)
head(m)
head(n)
j
j <- 12
max.clusters <- 20
cp.features <- merge(cp.spread, calendar.df[,c('Date','YearWeek')], by='Date')
train.weeks <- 12
test.weeks <- 1
max.clusters <- 20
set.seed(1234)
site.periods <- periods[periods > as.character(site.starts[site.starts$CustomerSiteId==sites[i],'YearWeek'])]
l <- length(site.periods)
l < (train.weeks+test.weeks)
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
# if the data set is too small, then skip forward in time
if(nrow(train.set) < 40) { break() }
# on the fly, determine the number of clusters for this data set
# print('entering section to determine k')
wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
if(length(which(k.curve < 0))==0) {
k.centers <- max.clusters
} else {
k.centers <- min(which(k.curve < 0)) - 1
}
# k.centers = 10
# perform k-means on the training set to get a cluster
# print('entering section to cluster using k-means')
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
rm(k)
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
train.set
j
site.periods
cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
sites[i]
site.periods
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
head(cp.features)
unique(cp.features[cp.features$CustomerSiteId=='26', 'YearWeek'])
site.periods
j+1
j-train.periods
j-train.weeks
j <- 13
train.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- sum(kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
if(length(which(k.curve < 0))==0) {
k.centers <- max.clusters
} else {
k.centers <- min(which(k.curve < 0)) - 1
}
k.centers
k.fit
k.fit$withinss
k.fit$size
head(predicted.set)
summary(k.ift)
summary(k.fit)
k.fit$centers
k.fit$betweenss
k.fit$totss
k.fit$betweenss/k.fit$totss
k.fit$withinss
k.fit$tot.withinss
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
train.set$Cluster <- as.factor(unname(k.fit$cluster))
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
train.set[, as.character(unique(cp.df$AssayName))]
k.fit <- kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers = k.centers, iter.max = 100)
train.set$Cluster <- as.factor(unname(k.fit$cluster))
k.knn <- train(Cluster~., data = train.set[, c(as.character(unique(cp.df$AssayName)),'Cluster')], method='knn')
predicted.set <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], as.character(unique(cp.df$AssayName))]
head(predicted.set)
wss <- (nrow(predicted.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(predicted.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- sum(kmeans(predicted.set[, as.character(unique(cp.df$AssayName))], centers=k)$withinss)
k.curve <- sapply(2:length(wss), function(x) (wss[x-1] - wss[x])/wss[x-1])
if(length(which(k.curve < 0))==0) {
k.centers.new <- max.clusters
} else {
k.centers.new <- min(which(k.curve < 0)) - 1
}
k.centers
k.centers.new
k.fit.new <- kmeans(predicted.set[, as.character(unique(cp.df$AssayName))], centers = k.centers.new, iter.max = 100)
k.fit.new$withinss
k.fit$centers
k.fit.new$centers
predicted.set$Cluster <- predict(k.knn, newdata = predicted.set)
head(predicted.set)
site.periods[j+1]
z <- cp.features[cp.features$CustomerSiteId==sites[i] & cp.features$YearWeek <= site.periods[j+1] & cp.features$YearWeek >= site.periods[(j-train.weeks)], ]
head(z)
z <- z[with(z, order(YearWeek)), ]
View(z)
k.fit$size
k.fit.new$size
head(predicted.set)
max(predicted.set$Cluster)
max(as.character(predicted.set$Cluster))
summary(k.fit)
wss <- (nrow(train.set[, as.character(unique(cp.df$AssayName))])-1)*sum(apply(train.set[, as.character(unique(cp.df$AssayName))], 2, var))
for (k in 2:max.clusters) wss[k] <- (kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$betweenss/kmeans(train.set[, as.character(unique(cp.df$AssayName))], centers=k)$totss)
wss
max(wss[wss<1])
wss[wss = max(wss[wss<1])]
which(wss = max(wss[wss<1]))
max(wss[wss<1])
plot(x=seq(1,20,1), y=wss)
plot(x=seq(2,20,1), y=wss[2:20])
