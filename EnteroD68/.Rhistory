period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
site.period.df$Key <- j
site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
head(site.df)
unique(site.df[site.df$YearWeek=='2014-33','Key'])
ggplot(subset(site.df, Key > 1010 & Key < 1050), aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + facet_wrap(~Key)
head(site.features)
run.ids <- unique(cp.median$RunDataId)
cp.ordered <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(cp.median[cp.median$RunDataId==run.ids[x], ][order(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), ], Index = seq(1, length(cp.median[cp.median$RunDataId==run.ids[x], 'Cp']), 1))))
cp.sequence <- do.call(rbind, lapply(1:length(run.ids), function(x) data.frame(RunDataId = run.ids[x], Sequence = paste(as.character(cp.ordered[cp.ordered$RunDataId==run.ids[x], 'AssayName']), collapse=', '))))
head(cp.sequence)
unique(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))
grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])))
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))[!(unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])) %in% grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))))]
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))[!(unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])) %in% unique(as.character(grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))))))]
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))[grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])))]
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])) == unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))[grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])))]
unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])) != unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence']))[grep('Entero', unique(as.character(cp.sequence[grep('^HRV4', cp.sequence$Sequence), 'Sequence'])))]
unique(as.character(cp.sequence[grep('^HRV4.', cp.sequence$Sequence), 'Sequence']))
unique(as.character(cp.sequence[grep('^HRV4$', cp.sequence$Sequence), 'Sequence']))
unique(as.character(cp.sequence[grep('^HRV4$|^HRV4, HRV1$|^HRV4, HRV1, HRV2$|^HRV4, HRV1, HRV2, HRV3$', cp.sequence$Sequence), 'Sequence']))
unique(as.character(cp.sequence[grep('^HRV4$|^HRV4, HRV1$|^HRV4, HRV1, HRV2$|^HRV4, HRV1, HRV2, HRV3$', cp.sequence$Sequence), 'Sequence']))
head(cp.sequence)
cp.sequence[as.character(cp.sequence$Sequence) %in% unique(as.character(cp.sequence[grep('^HRV4$|^HRV4, HRV1$|^HRV4, HRV1, HRV2$|^HRV4, HRV1, HRV2, HRV3$', cp.sequence$Sequence), 'Sequence'])), 'RunDataId']
mark.pos <- cp.sequence[as.character(cp.sequence$Sequence) %in% unique(as.character(cp.sequence[grep('^HRV4$|^HRV4, HRV1$|^HRV4, HRV1, HRV2$|^HRV4, HRV1, HRV2, HRV3$', cp.sequence$Sequence), 'Sequence'])), 'RunDataId']
head(site.features)
site.features[site.features$RunDataId %in% mark.pos, 'Signature'] <- 1
site.features[is.na(site.features$Signature), 'Signature'] <- 0
head(site.features)
ggplot(site.features, aes(x=as.factor(Obs), fill=Signature)) + geom_bar()
ggplot(site.features, aes(x=YearWeek, fill=Signature)) + geom_bar()
ggplot(site.features, aes(x=YearWeek, fill=as.factor(Signature))) + geom_bar()
View(site.features)
ggplot(subset(site.df, Key > 950 & Key < 1000), aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + facet_wrap(~Key)
ggplot(subset(site.df, Key > 1000 & Key < 1050), aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + facet_wrap(~Key)
site.test.pca
site.test.pca[site.test.pca$Cluster==0, ]
length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
print(test.noise, 'observations are noise in the test set at j=', j, sep=' ')
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
# this section was using weeks as the breaks, which is arbitrary... Try rolling by sequence instead
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
print(paste(test.noise, 'observations are noise in the test set at j=', j, sep=' '))
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
clust.count <- max(as.numeric(as.character(site.train.pca$Cluster)))
print(paste(test.noise, 'observations are noise in the test set at j=', j, ' and there are', clust.count, 'clusters.', sep=' '))
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
head(site.train.pca)
max(as.numeric(as.character(site.train.pca$Cluster)))
unique(site.train.pca$Cluster)
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
clust.count <- max(as.numeric(as.character(site.train.pca$Cluster)))+1
temp.df <- data.frame(Index = j, ClusterCount = clust.count, NoisePoints = test.noise)
site.df <- rbind(site.df, temp.df)
# print(paste(test.noise, 'observations are noise in the test set at j=', j, ' and there are', clust.count, 'clusters.', sep=' '))
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
head(site.df)
plot(x=ClusterCount, y=NoisePoints)
plot(x=ClusterCount, y=NoisePoints, data=site.df)
with(site.df, plot(ClusterCount, NoisePoints))
site.df$Record <- 1
a <- with(site.df, aggregate(Record~ClusterCount+NoisePoints, FUN=sum))
head(a)
a
head(a)
ggplot(a, aes(x=ClusterCount, y=NoisePoints, color=Record)) + geom_point()
ggplot(a, aes(x=ClusterCount, y=NoisePoints, color=Record)) + geom_point(size=5)
head(site.df)
ggplot(a, aes(x=as.factor(Index), y=NoisePoints, fill=as.factor(ClusterCount))) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=NoisePoints, fill=as.factor(ClusterCount))) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=NoisePoints-ClusterCount)) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=(NoisePoints*ClusterCount))) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=(NoisePoints/ClusterCount))) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=(ClusterCount-NoisePoints))) + geom_bar(stat='identity')
ggplot(site.df, aes(x=as.factor(Index), y=NoisePoints-ClusterCount)) + geom_bar(stat='identity')
guess.eps
j
guess.eps
noise.ratio
head(site.test)
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
clust.count <- max(as.numeric(as.character(site.train.pca$Cluster)))+1
temp.df <- data.frame(Index = j, ClusterCount = clust.count, NoisePoints = test.noise, Eps = guess.eps, NoiseRation = noise.ratio, StartDate = min(site.train$Date), StopDate = max(site.test$Date))
site.df <- rbind(site.df, temp.df)
# print(paste(test.noise, 'observations are noise in the test set at j=', j, ' and there are', clust.count, 'clusters.', sep=' '))
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
head(site.df)
ggplot(site.df, aes(x=StartDate, y=ClusterCount)) + geom_line()
ggplot(site.df, aes(x=StartDate, y=Eps)) + geom_line()
ggplot(site.df, aes(x=StartDate, y=NoiseRation)) + geom_line()
site.df$StopDate - site.df$StartDate
unname(site.df$StopDate - site.df$StartDate)
a <- site.df$StopDate - site.df$StartDate
a
rm(a)
head(site.df)
site.df$ObsWindowInDays <- site.df$StopDate - site.df$StartDate
head(site.df)
site.df$ObsWindowInDays <- as.numeric(site.df$StopDate - site.df$StartDate)
head(site.df)
head(site.df)
ggplot(site.df, aes(x=StopDate, y=Eps, color=ObsWindowInDays)) + geom_point()
ggplot(site.df, aes(x=StopDate, y=NoiseRation, color=ObsWindowInDays)) + geom_point()
ggplot(site.df, aes(x=StopDate, y=ClusterCount, color=ObsWindowInDays)) + geom_point()
ggplot(site.df, aes(x=StopDate, y=Eps, color=as.factor(NoisePoints))) + geom_point()
ggplot(site.df, aes(x=StopDate, y=Eps, color=as.factor(ClusterCount))) + geom_point()
site.df$Score <- with(site.df, (ClusterCount + 1/Eps + NoisePoints)/ObsWindowInDays)
head(site.df)
ggplot(site.df, aes(x=StopDate, y=Score)) + geom_line()
View(sites.df)
View(site.df)
cp.features <- merge(cp.clean, calendar.df[,c('Date','YearWeek')], by='Date')
cp.features <- cp.features[with(cp.features, order(CustomerSiteId, Date)), ]
sites <- unique(cp.features$CustomerSiteId)[order(unique(cp.features$CustomerSiteId))]
# train.weeks <- 12
# test.weeks <- 1
# max.clusters <- 20
initial.window <- 100
test.horizon <- 10
scored.df <- c()
for (i in 1:length(sites)) {
# parition the data by site and set up a timeframe
site.start <- as.character(site.starts[site.starts$CustomerSiteId==sites[i], 'YearWeek'])
site.features <- cp.features[cp.features$CustomerSiteId==sites[i] & as.character(cp.features$YearWeek) > site.start, ]
site.features <- site.features[with(site.features, order(Date)), ]
site.features$Obs <- seq(1, length(site.features$Date), 1)
# this section was using weeks as the breaks, which is arbitrary... Try rolling by sequence instead
site.df <- c()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
# preprocess data using the PCA method
set.seed(1234)
period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on reducing the ratio of points considered as noise to some threshold
guess.eps <- 0.01
guess.mpt <- 10
noise.threshold <- 0.10
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
while(noise.threshold < noise.ratio) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
}
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
test.noise <- length(site.test.pca[site.test.pca$Cluster==0, 'Cluster'])
clust.count <- max(as.numeric(as.character(site.train.pca$Cluster)))+1
temp.df <- data.frame(Index = j, CustomerSiteId = sites[i], ClusterCount = clust.count, NoisePoints = test.noise, Eps = guess.eps, NoiseRation = noise.ratio, StartDate = min(site.train$Date), StopDate = max(site.test$Date))
temp.df$ObsWindowInDays <- as.numeric(temp.df$StopDate - temp.df$StartDate)
temp.df$Score <- (temp.df$ClusterCount + 1/temp.df$Eps + temp.df$NoisePoints)/temp.df$ObsWindowInDays
site.df <- rbind(site.df, temp.df)
# print(paste(test.noise, 'observations are noise in the test set at j=', j, ' and there are', clust.count, 'clusters.', sep=' '))
# site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId','Obs')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId','Obs')], site.test.pca)))
# site.period.df$PCs <- length(colnames(site.period.df)[grep('^PC', colnames(site.period.df))])
# site.period.df$Key <- j
# site.period.df <- site.period.df[,c('YearWeek','Obs','Cluster','Key')]
# site.df <- rbind(site.df, site.period.df)
# ggplot(site.period.df, aes(x=as.factor(Obs), fill=Cluster)) + geom_bar() + labs(title = paste('Cluster Prediction at j =', j, sep=' '), x='Observation')
}
scored.df <- rbind(scored.df, site.df)
if(FALSE) {
# # every "train.weeks" consecutive period will be used as the train set and then the forward "test.weeks" period will be predicted
# site.train.periods <- unique(cp.features[cp.features$YearWeek > site.start, 'YearWeek'])
#
# for(j in (train.weeks+2):(length(site.train.periods)-test.weeks)) {
#
#   site.train <- site.features[site.features$YearWeek >= (site.train.periods[j-train.weeks]) & site.features$YearWeek <= site.train.periods[j], ]
#   site.test <- site.features[site.features$YearWeek == site.train.periods[j+1], ]
#
#   if(nrow(site.train) < 50) { break() }
#
#   # preprocess data using the PCA method
#   set.seed(1234)
#   period.pca.trans <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
#   site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
#   site.test.pca <- predict(period.pca.trans, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
#
#   # apply dbscan to the train data set... determine eps based on minimizing the ratio of points considered as noise
#   guess.eps <- 0.01
#   guess.mpt <- 10
#   noise.threshold <- 0.10
#   eps.interval <- 0.01
#   guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
#   noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
#
#   while(noise.threshold < noise.ratio) {
#
#     guess.eps <- guess.eps + eps.interval
#     guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
#     noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
#   }
#
#   # with the "correct" dbscan clustering, predict the clusters for the test data
#   site.train.pca$Cluster <- as.factor(guess.res$cluster)
#   site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,colnames(site.train.pca)[grep('^PC', colnames(site.train.pca))]],
#                                    site.test.pca[,colnames(site.test.pca)[grep('^PC', colnames(site.test.pca))]]))
#
#
#   site.period.df <- rbind(data.frame(cbind(site.train[,c('YearWeek','CustomerSiteId')], site.train.pca)), data.frame(cbind(site.test[,c('YearWeek','CustomerSiteId')], site.test.pca)))
#   ggplot(site.period.df, aes(x=YearWeek, fill=Cluster)) + geom_bar()
#
#
#   # I THINK THAT THERE IS SOMETHING HERE, BUT USING THE 95% CI ON THE NOISE CLUSTER DENSITY IS WAY TOO SENSITIVE
#   site.agg <- with(data.frame(site.period.df, Count=1), aggregate(Count~YearWeek+Cluster, FUN=sum))
#   fill.periods <- unique(site.agg$YearWeek)[order(unique(site.agg$YearWeek))]
#   clusters <- max(as.numeric(as.character(site.agg$Cluster)))
#   place.hold <- do.call(rbind, lapply(1:length(fill.periods), function(x) data.frame(YearWeek = fill.periods[x], Cluster = as.factor(seq(0, clusters, 1)))))
#   site.agg.fill <- merge(place.hold, site.agg, by=c('YearWeek','Cluster'), all=TRUE)
#   site.agg.fill[is.na(site.agg.fill$Count), 'Count'] <- 0
#   site.agg.fill <- merge(site.agg.fill, with(site.agg.fill, aggregate(Count~YearWeek, FUN=sum)), by='YearWeek')
#   colnames(site.agg.fill) <- c('YearWeek','Cluster','ClusterCount','Observations')
#   site.agg.fill$Portion <- with(site.agg.fill, ClusterCount/Observations)
#   site.ci.info <- merge(merge(with(site.agg.fill[as.character(site.agg.fill$YearWeek)!=max(as.character(site.agg.fill$YearWeek)), ], aggregate(Portion~Cluster, FUN=mean)), with(site.agg.fill[as.character(site.agg.fill$YearWeek)!=max(as.character(site.agg.fill$YearWeek)), ], aggregate(Portion~Cluster, FUN=sd)), by='Cluster'), with(site.agg.fill[as.character(site.agg.fill$YearWeek)!=max(as.character(site.agg.fill$YearWeek)), ], aggregate(ClusterCount~Cluster, FUN=sum)), by='Cluster')
#   colnames(site.ci.info) <- c('Cluster','sMean','sSdev','n')
#   flag <- (site.ci.info[site.ci.info$Cluster==0,'sMean'] + qnorm(0.975)*site.ci.info[site.ci.info$Cluster==0, 'sSdev']/sqrt(site.ci.info[site.ci.info$Cluster==0, 'n'])) < site.agg.fill[site.agg.fill$Cluster==0 & as.character(site.agg.fill$YearWeek)==max(as.character(site.agg.fill$YearWeek)),'Portion']
#
#   if(flag) {
#
#     message <- paste('For site', sites[i], 'at time period', site.train.periods[j+1], '(j = ', j, ')','there would be an anomaly.', sep=' ')
#     print(message)
#     break()
#   }
# }
}
}
head(scored.df)
ggplot(scored.df, aes(x=StopDate, y=Score)) + geom_bar(stat='identity') + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=StopDate, y=Score)) + geom_line() + facet_wrap(~CustomerSiteId, scale='free_y')
head(site.df)
hist(site.df$ObsWindowInDays)
head(scored.df)
hist(scored.df$ObsWindowInDays)
ggplot(scored.df, aes(x=StopDate, y=ObsWindowInDays, group=CustomerSiteId)) + geom_line()
ggplot(scored.df, aes(x=StopDate, y=ObsWindowInDays)) + geom_line() + facet_wrap(~CustomerSiteId)
head(scored.df)
scored.df$MultScore <- with(scored.df, Score*ObsWindowInDays)
ggplot(scored.df, aes(x=StopDate, y=MultScore)) + geom_line() + facet_wrap(~CustomerSiteId, scale='free_y')
ggplot(scored.df, aes(x=StopDate, y=(NoisePoints/Eps))) + geom_line() + facet_wrap(~CustomerSiteId, scale='free_y')
ggplot(scored.df, aes(x=StopDate, y=(NoisePoints/10 + Eps))) + geom_line() + facet_wrap(~CustomerSiteId, scale='free_y')
ggplot(scored.df, aes(x=StopDate, y=(NoisePoints))) + geom_line() + facet_wrap(~CustomerSiteId, scale='free_y')
with(scored.df, plot(x=ClusterCount, y=Eps))
guess.eps
dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
guess.eps <- 1
guess.mpt <- 80
cluster.max <- 2
dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
guess.eps <- 1
guess.mpt <- 20
cluster.max <- 2
dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
heas(site.train.pca)
head(site.train.pca)
dbscan(site.train.pca[,1:3], eps = guess.eps, minPts = guess.mpt)
guess.eps <- 1
guess.mpt <- 80
cluster.max <- 2
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
dbscan(site.train.pca[,1:3], eps = guess.eps, minPts = guess.mpt)
cluster.init <- 0
site.train.pca <- predict(period.pca.trans, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
guess.eps <- 1
guess.mpt <- 80
cluster.max <- 2
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- 0
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
guess.rew
guess.res
guess.res$cluster
max(guess.res$cluster)
guess.eps <- 1
guess.mpt <- 80
cluster.max <- 2
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
eps.interval <- 0.01
cluster.init <- 0
while(cluster.int < cluster.max) {
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- guess.res$cluster
guess.eps <- guess.eps + eps.interval
}
while(cluster.init < cluster.max) {
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- guess.res$cluster
guess.eps <- guess.eps + eps.interval
}
while(cluster.init < cluster.max) {
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- guess.res$cluster
guess.eps <- guess.eps + eps.interval
print(cluster.init)
print(guess.eps)
}
guess.res$cluster
max(guess.res$cluster)
guess.eps <- 1
guess.mpt <- 80
cluster.max <- 2
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
eps.interval <- 0.01
cluster.init <- 0
while(cluster.init < cluster.max) {
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- max(guess.res$cluster)
guess.eps <- guess.eps + eps.interval
print(cluster.init)
print(guess.eps)
}
guess.eps <- 0.01
guess.mpt <- 80
cluster.max <- 2
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
eps.interval <- 0.01
cluster.init <- 0
while(cluster.init < cluster.max) {
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.init <- max(guess.res$cluster)
guess.eps <- guess.eps + eps.interval
print(cluster.init)
print(guess.eps)
}
guess.res
