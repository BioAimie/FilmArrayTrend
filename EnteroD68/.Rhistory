train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$DaysBetween[(x-9):x])*sum(as.numeric(as.character(temp$Cluster[(x-9):x])))))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
j <- j+1
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$DaysBetween[(x-9):x])*sum(as.numeric(as.character(temp$Cluster[(x-9):x])))))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
j <- j+1
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$DaysBetween[(x-9):x])*sum(as.numeric(as.character(temp$Cluster[(x-9):x])))))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
j <- j+1
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$DaysBetween[(x-9):x])*sum(as.numeric(as.character(temp$Cluster[(x-9):x])))))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
j <- j+1
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$DaysBetween[(x-9):x])*sum(as.numeric(as.character(temp$Cluster[(x-9):x])))))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
head(temp)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
temp$TrainDaysMean <- train.days.mean
temp$TestDaysMean <- test.days.mean
temp$TrainNoise <- train.noise
temp$TestNoise <- test.noise
temp$PCAs <- pca.count
head(temp)
temp$TrainDaysMean*temp$TrainNoise
ifelse(temp$Cluster==0, 1, 0)
temp$NoiseCount <- ifelse(temp$Cluster==0, 1, 0)
head(temp)
sapply(10:length(temp$Date), function(x) sum(temp$NoiseCount[(x-9):x])*mean(temp$PCAs[(x-9):x]))
sapply(10:length(temp$Date), function(x) (sum(temp$NoiseCount[(x-9):x])*mean(temp$PCAs[(x-9):x]))/mean(temp$DaysBetween[(x-9):x]))
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) sum(temp$NoiseCount[(x-9):x])*mean(temp$PCAs[(x-9):x])))
head(a)
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])*mean(temp$PCAs[(x-9):x])))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])+sd(temp$NoiseCount[(x-9):x])))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)), data = a)
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)+sd(SmoothScore)), data = a)
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)2*+sd(SmoothScore)), data = a)
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)+2*sd(SmoothScore)), data = a)
ifelse(a$SmoothScore > (mean(a$SmoothScore)+2*sd(a$SmoothScore)), 1, 0)
a$Outside <- ifelse(a$SmoothScore > (mean(a$SmoothScore)+2*sd(a$SmoothScore)), 1, 0)
tail(a)
a[(length(a$Date)-test.horizon), ]
a[(length(a$Date)-test.horizon):length(a$Date), ]
a[(length(a$Date)-test.horizon+1):length(a$Date), ]
a[(length(a$Date)-test.horizon):length(a$Date), ]
a[(length(a$Date)-test.horizon+1):length(a$Date), ]
a[(length(a$Date)-test.horizon+1):length(a$Date), 'Outside']
sum(a[(length(a$Date)-test.horizon+1):length(a$Date), 'Outside'])
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
guess.res
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
# temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
#                    TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
#                    TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
temp$TrainDaysMean <- train.days.mean
temp$TestDaysMean <- test.days.mean
temp$TrainNoise <- train.noise
temp$TestNoise <- test.noise
temp$PCAs <- pca.count
temp$NoiseCount <- ifelse(temp$Cluster==0, 1, 0)
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])))
a$SmoothScore <- predict(loess(Score~Obs, data = a))
a$Outside <- ifelse(a$SmoothScore > (mean(a$SmoothScore)+2*sd(a$SmoothScore)), 1, 0)
ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)+2*sd(SmoothScore)), data = a)
head(a)
temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
head(temp)
site.df <- c()
site.start.time <- Sys.time()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
j <- j+1
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
# temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
# temp$TrainDaysMean <- train.days.mean
# temp$TestDaysMean <- test.days.mean
# temp$TrainNoise <- train.noise
# temp$TestNoise <- test.noise
# temp$PCAs <- pca.count
# temp$NoiseCount <- ifelse(temp$Cluster==0, 1, 0)
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
# a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])))
# a$SmoothScore <- predict(loess(Score~Obs, data = a))
# a$Outside <- ifelse(a$SmoothScore > (mean(a$SmoothScore)+2*sd(a$SmoothScore)), 1, 0)
# ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)+2*sd(SmoothScore)), data = a)
site.df <- rbind(site.df, temp)
}
rnorm(10, 5, 2)
data.frame(Seq = seq(1, 10, 1), Key = 'Top', Value = rnorm(10, 5, 2))
rbind(data.frame(Seq = seq(1, 10, 1), Key = 'Top', Value = rnorm(10, 5, 2)), data.frame(Seq = seq(1, 10, 1), Key = 'Bottom', Value = rnorm(20, 5, 2)))
rbind(data.frame(Seq = seq(1, 10, 1), Key = 'Top', Value = rnorm(10, 5, 2)), data.frame(Seq = seq(1, 10, 1), Key = 'Bottom', Value = rnorm(20, 10, 2)))
d <- rbind(data.frame(Seq = seq(1, 10, 1), Key = 'Top', Value = rnorm(10, 5, 2)), data.frame(Seq = seq(1, 10, 1), Key = 'Bottom', Value = rnorm(20, 10, 2)))
head(d)
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, scale='free_y')
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, scale='free_y', ncol=1)
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, scale='free_y', ncol=1) + ylim(c(min(Value)-3, max(Value)+3))
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, scale='free_y', ncol=1) + ylim(c(min(Value)-3, max(Value)+3), data=d)
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, scale='free_y', ncol=1) + ylim(c(min(d$Value)-3, max(d$Value)+3))
ggplot(d, aes(x=Seq, y=Value, group=Key)) + geom_line() + facet_wrap(~Key, ncol=1) + ylim(c(min(d$Value)-3, max(d$Value)+3))
rm(d)
head(site.df)
ggplot(site.df, aes(x=Seq, y=TestNoise/TrainNoise)) + geom_point()
ggplot(site.df, aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point()
ggplot(subset(site.df, Seq < 1500), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point()
ggplot(subset(site.df, Seq < 1000), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point()
ggplot(subset(site.df, Seq < 1000), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth()
ggplot(subset(site.df, Seq < 1000), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
ggplot(subset(site.df, Seq < 1000), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='lm')
ggplot(subset(site.df, Seq < 1000), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='glm')
ggplot(subset(site.df, Seq < 500), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='glm')
ggplot(subset(site.df, Seq < 500), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='rlm')
ggplot(subset(site.df, Seq < 500), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='loess')
ggplot(subset(site.df, Seq < 500), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
ggplot(subset(site.df, Seq < 300), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
ggplot(subset(site.df, Seq < 400), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
head(site.df)
site.df[site.df$TestStartDate < as.Date('2014-09-01'), ]
max(site.df[site.df$TestStartDate < as.Date('2014-09-01'), 'Seq'])
ggplot(subset(site.df, Seq < 485), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
head(calendar.df)
calendar.df[calendar.df$Year == '2014-35', ]
calendar.df[calendar.df$YearWeek == '2014-35', ]
max(site.df[site.df$TestStartDate < as.Date('2014-08-30'), 'Seq'])
ggplot(subset(site.df, Seq < 460), aes(x=TestStartDate, y=TestNoise/TrainNoise)) + geom_point() + geom_smooth(method='gam')
site.df[site.df$Seq < 460, 'TestNoise']/site.df[site.df$Seq < 460, 'TrainNoise']
data.frame(site.df[site.df$Seq < 460, ], Score = site.df[site.df$Seq < 460, 'TestNoise']/site.df[site.df$Seq < 460, 'TrainNoise'])
head(site.df)
a <- data.frame(site.df[site.df$Seq < 460, ], Score = site.df[site.df$Seq < 460, 'TestNoise']/site.df[site.df$Seq < 460, 'TrainNoise'])
heaD(a)
head(a)
ggplot(a, aes(x=TestStartDate, y=Score)) + geom_point() + geom_smooth()
plot(a$TrainNoise, a$TestNoise)
lines(lm(TestNoise~TrainNoise), data=a)
abline(lm(TestNoise~TrainNoise), data=a)
abline(lm(TestNoise~TrainNoise))
abline(lm(a$TestNoise~a$TrainNoise))
ggplot(a, aes(x=TestStartDate, y=Score)) + geom_point() + geom_smooth()
ggplot(a, aes(x=TestStartDate, y=Score)) + geom_point() + geom_line(aes(x=TestStartDate, y=mean(Score)), data=a)
ggplot(a, aes(x=TestStartDate, y=Score)) + geom_point() + geom_line(aes(x=TestStartDate, y=mean(Score)+sd(Score)), data=a)
lm(Score~Seq, data=a)
summary(lm(Score~Seq, data=a))
residuals(lm(Score~Seq, data=a))
unname(residuals(lm(Score~Seq, data=a)))
ggplot(a, aes(x=TestStartDate, y=Score)) + geom_point() + geom_line(aes(x=TestStartDate, y=(Score - mean(Score))), data=a)
head(a)
max(0, a$Score - mean(a$Score))
a$Score - mean(a$Score)
head(a)
a$AdjScore <- a$Score - mean(a$Score)
head(a)
a[a$AdjScore > 0.3]
a[a$AdjScore > 0.3, ]
head(site.df)
heaD(a)
head(a)
head(a)
head(a)
a[a$AdjScore > 0.3, ]
head(site.df)
library(RODBC)
library(lubridate)
library(ggplot2)
library(mgcv)
library(devtools)
require(dateManip)
library(cluster)
library(caret)
library(dbscan)
library(C50)
library(tidyr)
library(dplyr)
library(rgl)
library(AnomalyDetection)
head(site.df)
temp
sites
i
head(temp)
temp$Score <- temp$TestNoise/temp$TrainNoise
temp$AdjScore <- temp$Score - mean(temp$Score)
temp$flag <- ifelse(temp$AdjScore > 0.3, 1, 0)
head(temp)
initial.window <- 100
test.horizon <- 10
sites <- c(13, 25, 26) # , 33, 36, 38)
scored.df <- c()
for (i in 1:length(sites)) {
# parition the data by site and set up a timeframe
site.start <- as.character(site.starts[site.starts$CustomerSiteId==sites[i], 'YearWeek'])
site.features <- cp.features[cp.features$CustomerSiteId==sites[i] & as.character(cp.features$YearWeek) > site.start, ]
site.features <- site.features[with(site.features, order(Date)), ]
if(nrow(site.features)==0) { next }
site.features$Obs <- seq(1, length(site.features$Date), 1)
site.features$DaysBetween <- c(0, as.numeric(sapply(2:length(site.features$Date), function(x) site.features[x,'Date']-site.features[(x-1),'Date'])))
site.df <- c()
site.start.time <- Sys.time()
for(j in (initial.window+1):(length(site.features$Obs)-test.horizon)) {
site.train <- site.features[site.features$Obs < j & site.features$Obs >= (j - initial.window), ]
site.test <- site.features[site.features$Obs < (j + test.horizon) & site.features$Obs >= j, ]
train.nzv <- nearZeroVar(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], saveMetrics = TRUE)
train.remove.vars <- row.names(train.nzv[train.nzv$nzv==TRUE,])
site.train <- site.train[,!(colnames(site.train) %in% train.remove.vars)]
site.test <- site.test[,!(colnames(site.test) %in% train.remove.vars)]
pca.tranform <- preProcess(site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))], method = 'pca')
site.train.pca <- predict(pca.tranform, site.train[,(colnames(site.train) %in% as.character(unique(cp.df$AssayName)))])
site.test.pca <- predict(pca.tranform, site.test[,(colnames(site.test) %in% as.character(unique(cp.df$AssayName)))])
# apply dbscan to the train data set... determine eps based on the point where there are 2 clusters (1 cluster + noise)
guess.eps <- 0.01
guess.mpt <- 90
eps.interval <- 0.01
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
cluster.int <- max(guess.res$cluster)
iter.start.time <- Sys.time()
while(cluster.int < 1) {
guess.eps <- guess.eps + eps.interval
guess.res <- dbscan(site.train.pca, eps = guess.eps, minPts = guess.mpt)
noise.ratio <- sum(guess.res$cluster==0)/length(guess.res$cluster)
cluster.int <- max(guess.res$cluster)
}
print(Sys.time() - iter.start.time)
# with the "correct" dbscan clustering, predict the clusters for the test data
site.train.pca$Cluster <- as.factor(guess.res$cluster)
site.test.pca$Cluster <- unname(predict(guess.res, site.train.pca[,grep('^PC', colnames(site.train.pca))], site.test.pca))
# count the number of clusters in the test set that are considered noise
pca.count <- max(grep('^PC', colnames(site.train.pca)))
train.noise <- nrow(site.train.pca[site.train.pca$Cluster==0, ])
test.noise <- nrow(site.test.pca[site.test.pca$Cluster==0, ])
train.days.mean <- mean(site.train$DaysBetween)
test.days.mean <- mean(site.test$DaysBetween)
train.days.median <- median(site.train$DaysBetween)
test.days.median <- median(site.test$DaysBetween)
temp <- data.frame(CustomerSiteId = sites[i], Seq = j, TestStartDate = site.test[site.test$Obs==min(site.test$Obs), 'Date'],
TrainNoise = train.noise, TestNoise = test.noise, PCAs = pca.count, TrainDaysMean = train.days.mean,
TrainDaysMedian = train.days.median, TestDaysMean = test.days.mean, TestDaysMedian = test.days.median)
temp$Score <- temp$TestNoise/temp$TrainNoise
temp$AdjScore <- temp$Score - mean(temp$Score)
temp$flag <- ifelse(temp$AdjScore > 0.3, 1, 0)
# temp <- rbind(data.frame(site.train, site.train.pca), data.frame(site.test, site.test.pca))
# temp$TrainDaysMean <- train.days.mean
# temp$TestDaysMean <- test.days.mean
# temp$TrainNoise <- train.noise
# temp$TestNoise <- test.noise
# temp$PCAs <- pca.count
# temp$NoiseCount <- ifelse(temp$Cluster==0, 1, 0)
## RIGHT HERE IS WHERE I NEED TO DO MORE WORK!!!
# a <- data.frame(temp[10:length(temp$Date), ], Score = sapply(10:length(temp$Date), function(x) mean(temp$NoiseCount[(x-9):x])))
# a$SmoothScore <- predict(loess(Score~Obs, data = a))
# a$Outside <- ifelse(a$SmoothScore > (mean(a$SmoothScore)+2*sd(a$SmoothScore)), 1, 0)
# ggplot(a, aes(x=Obs, y=Score)) + geom_smooth() + geom_line(aes(x=Obs, y=mean(SmoothScore)+2*sd(SmoothScore)), data = a)
site.df <- rbind(site.df, temp)
}
# LOOP WILL BE DONE, CHECK OUT site.df FOR SITE 13
# site.scored <- site.df
# site.scored$PCTrainWeightedScore <- mean(site.scored$TrainNoise) + site.scored$PCAs*sd(site.scored$TrainNoise)
# site.scored$PCTestWeightedScore <- mean(site.scored$TestNoise) + site.scored$PCAs*sd(site.scored$TestNoise)
# site.scored <- merge(site.scored, site.features[,c('Obs','Date','YearWeek')], by.x='Seq', by.y='Obs')
# site.scored <- cbind(site.scored[10:length(site.scored$TestNoise), ], TestNoiseSummed10 = sapply(10:length(site.scored$TestNoise), function(x) sum(site.scored[,'TestNoise'][(x-9):x])))
# site.scored$LoessPredict <- predict(loess((TestNoiseSummed10*PCAs)~Seq, data=site.scored))
# ggplot(site.scored, aes(x=Seq, y=TestNoiseSummed10*PCAs)) + geom_point() + geom_smooth(aes(outfit=fit<<-..y..), n=length(site.scored$TestNoise))
# site.scored$GamPredict <- fit
# p.plot <- ggplot(site.scored, aes(x=Date, y=GamPredict)) + geom_line(lwd=1.5) + geom_line(aes(x=Date, y=mean(GamPredict)+sd(GamPredict)), data=site.scored, color='red', lwd=1.5) + theme(panel.background = element_rect(fill='white',color='white'), axis.text=element_text(color='black', face='bold'), text=element_text(face='bold', size=20)) + labs(title=paste('Site', sites[i], 'at time', max(site.scored$Date), sep=' '), x='Date', y='Noise-GAM Score')
# predict(loess((TestNoiseSummed10*PCAs)~Seq, data=site.scored))
print(Sys.time() - site.start.time)
scored.df <- rbind(scored.df, site.df)
}
head(site.df)
ggplot(site.df, aes(x=Seq, y=Score, color=as.factor(flag))) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=Seq, y=Score, color=as.factor(flag))) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=Seq, y=AdjScore, color=as.factor(flag))) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=Seq, y=TestNoise/TrainNoise)) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=Seq, y=PCAs*TestNoise/TrainNoise)) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=StartTestDate, y=PCAs*TestNoise/TrainNoise)) + geom_point() + facet_wrap(~CustomerSiteId)
ggplot(scored.df, aes(x=TestStartDate, y=PCAs*TestNoise/TrainNoise)) + geom_point() + facet_wrap(~CustomerSiteId)
